{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "import torch\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ¤”æ€è€ƒï¼šå¦‚ä½•åŠ è½½æ•°æ®ï¼Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"labels.txt\", \"r\") as f:\n",
    "    raw = f.readlines() #è¯»å–æ‰€æœ‰è¡Œ\n",
    "\n",
    "tags = []\n",
    "data = []\n",
    "for l in raw:\n",
    "    tags.append(int(l[0]))#æ¯è¡Œçš„ç¬¬ä¸€ä¸ªå­—ç¬¦æ˜¯æ ‡ç­¾\n",
    "    d = l[1:-1]#å»æ‰æ ‡ç­¾å’Œæ¢è¡Œç¬¦\n",
    "    d = map(float, tuple(d)) #å°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºtupleï¼Œæ•°å­—è½¬æ¢ä¸ºfloatï¼Œæ–¹ä¾¿åç»­è½¬ä¸ºtensor\n",
    "    #tupleç›¸å¯¹äºlistæ›´çœå†…å­˜ï¼Œå› ä¸ºtupleæ˜¯ä¸å¯å˜çš„ï¼Œå¯¹è±¡æ‰€å«methodæ›´å°‘\n",
    "    data.append(tuple(d))\n",
    "\n",
    "#å°†æ ‡ç­¾å’Œæ•°æ®è½¬ä¸ºtensorï¼Œæ–¹ä¾¿åç»­åˆ‡åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†\n",
    "data = torch.tensor(data)\n",
    "tags = torch.tensor(tags)\n",
    "\n",
    "#åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†\n",
    "train_test_ratio = 0.8 #è®­ç»ƒé›†å æ€»æ•°æ®é›†çš„æ¯”ä¾‹\n",
    "\n",
    "train_size = int(train_test_ratio * len(data)) #è®­ç»ƒé›†å¤§å°\n",
    "test_size = len(data) - train_size #æµ‹è¯•é›†å¤§å°\n",
    "\n",
    "# åˆ‡åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†\n",
    "data_train = data[:train_size]\n",
    "data_test  = data[train_size:]\n",
    "tags_train = tags[:train_size]\n",
    "tags_test  = tags[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç›´æ¥å¥—ç”¨d2lç½‘ç«™ä¸Šçš„ä»£ç ï¼Œæ²¡æœ‰æ”¹åŠ¨\n",
    "def data_iter(batch_size, features, labels):\n",
    "    num_examples = len(features)\n",
    "    indices = list(range(num_examples))\n",
    "    # è¿™äº›æ ·æœ¬æ˜¯éšæœºè¯»å–çš„ï¼Œæ²¡æœ‰ç‰¹å®šçš„é¡ºåº\n",
    "    random.shuffle(indices)\n",
    "    for i in range(0, num_examples, batch_size):\n",
    "        batch_indices = torch.tensor(indices[i: min(i + batch_size, num_examples)])\n",
    "        yield features[batch_indices], labels[batch_indices]\n",
    "\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "w = torch.normal(0, 0.01, size=(len(data[0]), 1), requires_grad=True, dtype=torch.float32) #å¯¹æ¯ä¸ªåƒç´ éƒ½æœ‰ä¸€ä¸ªæƒé‡\n",
    "b = torch.zeros(1, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ‘‡æ–¹æ¡ˆ1ï¼šLinear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®­ç»ƒæ¨¡å‹\n",
    "def linreg(X, w, b):\n",
    "    return torch.matmul(X, w) + b\n",
    "\n",
    "# æŸå¤±å‡½æ•°\n",
    "def mse_loss(y_pred, y_true):\n",
    "    return torch.mean((y_pred - y_true)**2)\n",
    "\n",
    "# ä¼˜åŒ–å™¨\n",
    "def sgd(params, lr, batch_size):\n",
    "    \"\"\"å°æ‰¹é‡éšæœºæ¢¯åº¦ä¸‹é™\"\"\"\n",
    "    with torch.no_grad():\n",
    "        for param in params:    \n",
    "            param -= lr * param.grad / batch_size\n",
    "            param.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sgdä¼˜åŒ–å™¨æ•°å­¦åŸç†ï¼š\n",
    "- è®¡ç®—æ¢¯åº¦ï¼š$\\mathbf{g} \\leftarrow \\partial_{(\\mathbf{w},b)} \\frac{1}{|\\mathcal{B}|} \\sum_{i \\in \\mathcal{B}} l(\\mathbf{x}^{(i)}, y^{(i)}, \\mathbf{w}, b)$\n",
    "  - å…¶ä¸­$l$æ˜¯æŸå¤±å‡½æ•°ï¼Œ$\\mathcal{B}$æ˜¯è®­ç»ƒé›†ï¼Œ$\\mathbf{x}^{(i)}$æ˜¯ç¬¬$i$ä¸ªæ ·æœ¬çš„è¾“å…¥ï¼Œ$y^{(i)}$æ˜¯ç¬¬$i$ä¸ªæ ·æœ¬çš„æ ‡ç­¾ï¼Œ$\\mathbf{w}$å’Œ$b$æ˜¯æ¨¡å‹å‚æ•°\n",
    "- æ›´æ–°å‚æ•°ï¼š$\\mathbf{w} \\leftarrow \\mathbf{w} - \\eta \\cdot \\mathbf{g}$ï¼Œ\n",
    "- $\\eta$ æ˜¯å­¦ä¹ ç‡ï¼Œæ§åˆ¶æ›´æ–°æ­¥é•¿\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01, correct rate on training set: 0.88%\n",
      "epoch 02, correct rate on training set: 10.56%\n",
      "epoch 03, correct rate on training set: 21.41%\n",
      "epoch 04, correct rate on training set: 10.56%\n",
      "epoch 05, correct rate on training set: 0.00%\n",
      "epoch 06, correct rate on training set: 11.14%\n",
      "epoch 07, correct rate on training set: 10.26%\n",
      "epoch 08, correct rate on training set: 12.02%\n",
      "epoch 09, correct rate on training set: 9.97%\n",
      "epoch 10, correct rate on training set: 10.26%\n",
      "epoch 11, correct rate on training set: 12.02%\n",
      "epoch 12, correct rate on training set: 10.26%\n",
      "epoch 13, correct rate on training set: 0.59%\n",
      "epoch 14, correct rate on training set: 9.38%\n",
      "epoch 15, correct rate on training set: 12.90%\n",
      "epoch 16, correct rate on training set: 21.99%\n"
     ]
    }
   ],
   "source": [
    "lr = 0.02\n",
    "num_epochs = 16\n",
    "net = linreg\n",
    "loss = mse_loss\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for X, y in data_iter(batch_size, data_train, tags_train):\n",
    "        l = loss(net(X, w, b), y)  # Xå’Œyçš„å°æ‰¹é‡æŸå¤±\n",
    "        # å› ä¸ºlå½¢çŠ¶æ˜¯(batch_size,1)ï¼Œè€Œä¸æ˜¯ä¸€ä¸ªæ ‡é‡ã€‚lä¸­çš„æ‰€æœ‰å…ƒç´ è¢«åŠ åˆ°ä¸€èµ·ï¼Œ\n",
    "        # å¹¶ä»¥æ­¤è®¡ç®—å…³äº[w,b]çš„æ¢¯åº¦\n",
    "        l.sum().backward() # åå‘ä¼ æ’­\n",
    "        # ä½¿ç”¨å°æ‰¹é‡éšæœºæ¢¯åº¦ä¸‹é™æ›´æ–°å‚æ•°\n",
    "        sgd([w, b], lr, batch_size) \n",
    "    with torch.no_grad():\n",
    "        tags_pred = torch.round(net(data_train, w, b)).reshape(tags_train.shape)\n",
    "        acc_num = (tags_pred == tags_train).sum().item()  # è®¡ç®—é¢„æµ‹æ­£ç¡®çš„æ ·æœ¬æ•°\n",
    "        print(f'epoch {epoch + 1:02d}, correct rate on training set: {acc_num/len(data_train)*100:.02f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct rate on test set: 23.26%\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    train_l = torch.round(net(data_test, w, b)).reshape(tags_test.shape) == tags_test  # è®­ç»ƒé›†ä¸Šçš„æŸå¤±\n",
    "    print(f'correct rate on test set: {train_l.sum()/len(tags_test)*100:.02f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ‘†å¯ä»¥çœ‹åˆ°ï¼Œæ­£ç¡®ç‡å¾ˆä½ä¸Šä¸å»ï¼Œè¯´æ˜å¯èƒ½ä¸å­˜åœ¨çº¿æ€§å¯åˆ†çš„æƒ…å†µï¼Œéœ€è¦æ›´æ¢å…¶ä»–å›å½’æ¨¡å‹ã€‚ä¾‹å¦‚ï¼Œå†³ç­–æ ‘ã€éšæœºæ£®æ—ã€æ”¯æŒå‘é‡æœºç­‰ã€‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
