{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "import torch\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🤔思考：如何加载数据？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"labels.txt\", \"r\") as f:\n",
    "    raw = f.readlines()\n",
    "\n",
    "tags = []\n",
    "data = []\n",
    "for l in raw:\n",
    "    tags.append(int(l[0]))#每行的第一个字符是标签\n",
    "    d = l[1:-1]#去掉标签和换行符\n",
    "    d = map(float, tuple(d)) #将字符串转换为tuple，数字转换为float，方便后续转为tensor\n",
    "    #tuple相对于list更省内存，因为tuple是不可变的，对象所含method更少\n",
    "    data.append(tuple(d))\n",
    "\n",
    "#将标签和数据转为tensor，方便后续切分训练集和测试集\n",
    "data = torch.tensor(data)\n",
    "tags = torch.tensor(tags)\n",
    "\n",
    "#划分训练集和测试集\n",
    "train_test_ratio = 0.8\n",
    "train_size = int(train_test_ratio * len(data))\n",
    "test_size = len(data) - train_size\n",
    "data_train = data[:train_size]\n",
    "data_test  = data[train_size:]\n",
    "tags_train = tags[:train_size]\n",
    "tags_test  = tags[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直接套用d2l网站上的代码，没有改动\n",
    "def data_iter(batch_size, features, labels):\n",
    "    num_examples = len(features)\n",
    "    indices = list(range(num_examples))\n",
    "    # 这些样本是随机读取的，没有特定的顺序\n",
    "    random.shuffle(indices)\n",
    "    for i in range(0, num_examples, batch_size):\n",
    "        batch_indices = torch.tensor(indices[i: min(i + batch_size, num_examples)])\n",
    "        yield features[batch_indices], labels[batch_indices]\n",
    "\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "w = torch.normal(0, 0.01, size=(len(data[0]), 1), requires_grad=True, dtype=torch.float32) #对每个像素都有一个权重\n",
    "b = torch.zeros(1, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👇方案3：Multi-Layer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(nn.Linear(384, 128),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(128, 10))\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.normal_(m.weight, std=0.01)\n",
    "\n",
    "net.apply(init_weights)  # 初始化权重\n",
    "batch_size, lr, num_epochs = 32, 0.1, 16  # 设置超参数\n",
    "loss = nn.CrossEntropyLoss(reduction='none') # 定义损失函数\n",
    "trainer = torch.optim.SGD(net.parameters(), lr=lr) # 定义优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, test acc 0.140\n",
      "epoch 2, test acc 0.430\n",
      "epoch 3, test acc 0.837\n",
      "epoch 4, test acc 0.965\n",
      "epoch 5, test acc 0.965\n",
      "epoch 6, test acc 0.965\n",
      "epoch 7, test acc 0.965\n",
      "epoch 8, test acc 0.965\n",
      "epoch 9, test acc 0.965\n",
      "epoch 10, test acc 0.965\n",
      "epoch 11, test acc 0.965\n",
      "epoch 12, test acc 0.965\n",
      "epoch 13, test acc 0.965\n",
      "epoch 14, test acc 0.965\n",
      "epoch 15, test acc 0.965\n",
      "epoch 16, test acc 0.965\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for X, y in data_iter(batch_size, data_train, tags_train):\n",
    "        y_hat = net(X)\n",
    "        l = loss(y_hat, y)\n",
    "        l = l.mean()\n",
    "        trainer.zero_grad()\n",
    "        l.backward()\n",
    "        trainer.step()\n",
    "    acc_sum, n = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter(batch_size, data_test, tags_test):\n",
    "            y_hat = net(X)\n",
    "            acc_sum += (y_hat.argmax(dim=1) == y).float().sum().item()\n",
    "            n += y.shape[0]\n",
    "    # n = test_size\n",
    "    test_acc = acc_sum / n\n",
    "    print('epoch %d, test acc %.3f' % (epoch + 1, test_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
