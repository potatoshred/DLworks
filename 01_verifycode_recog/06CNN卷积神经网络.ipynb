{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "import torch\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🤔思考：如何加载数据？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"labels.txt\", \"r\") as f:\n",
    "    raw = f.readlines()\n",
    "\n",
    "tags = []\n",
    "data = []\n",
    "for l in raw:\n",
    "    tags.append(int(l[0]))#每行的第一个字符是标签\n",
    "    d = l[1:-1]#去掉标签和换行符\n",
    "    d = map(float, tuple(d)) #将字符串转换为tuple，数字转换为float，方便后续转为tensor\n",
    "    #tuple相对于list更省内存，因为tuple是不可变的，对象所含method更少\n",
    "    d = np.array(tuple(d)).reshape(24, 16).astype(np.float32) #将tuple转换为24x16的numpy数组，并转为float32类型\n",
    "    data.append(d)\n",
    "\n",
    "#将标签和数据转为tensor，方便后续切分训练集和测试集\n",
    "data = torch.tensor(data)\n",
    "tags = torch.tensor(tags)\n",
    "\n",
    "#划分训练集和测试集\n",
    "train_test_ratio = 0.8\n",
    "train_size = int(train_test_ratio * len(data))\n",
    "test_size = len(data) - train_size\n",
    "data_train = data[:train_size]\n",
    "data_test  = data[train_size:]\n",
    "tags_train = tags[:train_size]\n",
    "tags_test  = tags[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直接套用d2l网站上的代码，没有改动\n",
    "def data_iter(batch_size, features, labels):\n",
    "    num_examples = len(features)\n",
    "    indices = list(range(num_examples))\n",
    "    # 这些样本是随机读取的，没有特定的顺序\n",
    "    random.shuffle(indices)\n",
    "    for i in range(0, num_examples, batch_size):\n",
    "        batch_indices = torch.tensor(indices[i: min(i + batch_size, num_examples)])\n",
    "        yield features[batch_indices], labels[batch_indices]\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "w = torch.normal(0, 0.01, size=(len(data[0]), 1), requires_grad=True, dtype=torch.float32) #对每个像素都有一个权重\n",
    "b = torch.zeros(1, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👇方案4：Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数学原理：\n",
    "\n",
    "卷积神经网络（Convolutional Neural Network，CNN）是一种深度学习技术，它是由卷积层和池化层组成的。\n",
    "\n",
    "- 卷积定义：\n",
    "\n",
    "卷积，或译为叠积、褶积或旋积，是透过两个函数$f(x)$和$g(x)$的乘积，得到第三个函数$h(x)$的一种运算。\n",
    "公式：\n",
    "\n",
    "$h(x) = (f*g)(x) = \\int_{-\\infty}^{\\infty} f(t)g(x-t)dt$\n",
    "\n",
    "\n",
    "![image.png](./img/conv1.gif)\n",
    "\n",
    "\n",
    "- 卷积层：\n",
    "\n",
    "卷积层由多个卷积核组成，每个卷积核与输入图像的局部区域进行卷积操作，提取图像的特征。\n",
    "\n",
    "![image.png](./img/conv2.gif)\n",
    "\n",
    "卷积核可以看作一种散列函数，它对输入图像的局部区域进行加权求和，将多维的数组映射到一维。然而，与传统的散列函数不同，滑动窗口在进行加权求和时考虑了输入区域的邻近关系，从而保留了一定的局部连续性。\n",
    "\n",
    "- 池化/汇聚层：池化层的作用是降低卷积层对图像的缩放程度，从而提高模型的鲁棒性。\n",
    "  * 最大池化：最大池化是指对卷积核覆盖的区域取最大值作为输出。意义是减少特征图的尺寸并提取主要特征，减少了参数量。\n",
    "  + 平均池化：平均池化是指对卷积核覆盖的区域取平均值作为输出。与最大池化相比，平均池化可以更平滑地缩减特征图的尺寸，而不太关注最显著的特征。更加关注图像中的整体分布和平均值，而不太关注局部细节。适用于提取图像分类任务中的一些全局信息。\n",
    "\n",
    "- 全连接层：\n",
    "\n",
    "全连接层的作用是将卷积层提取的特征连接到输出层，输出层的每个节点对应于输入图像的某个特征。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义CNN模型， 直接使用pytorch的API\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        return x\n",
    "\n",
    "# 定义评估函数\n",
    "def evaluate_accuracy(data_iter, net, device):\n",
    "    ...\n",
    "\n",
    "# 定义训练函数\n",
    "def train_cnn():\n",
    "    ...\n",
    "    print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f')\n",
    "\n",
    "\n",
    "# 定义训练参数\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
